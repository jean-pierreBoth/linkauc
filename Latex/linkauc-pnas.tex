%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%Link AUC manuscript%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{article}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{authblk}
\usepackage{numprint}
\usepackage{siunitx}
%------------------------------------------------------------------------------
%  syles defined in linkauc.sty
\usepackage{625333_0_supp_latex_10774581_sbxt8w}
% ----------------------------------------------------------------------


\bibliographystyle{pnas2009}

\title{Link prediction: A centric precision or a centric AUC measure?}
\author[1,*]{Jean, Pierre Both}
\author[2]{Jianshu Zhao}
\affil[1]{Universit√© Paris-Saclay, CEA, List, Palaiseau, France. (Retired)}
\affil[2]{Center for Bioinformatics and Computational Genomics, Georgia Institute of Technology, Atlanta, Georgia, USA}
\affil[*]{Corresponding author : jeanpierre.both@gmail.com} 

\date{April 2024}

\begin{document}

\maketitle

\section{Introduction}

Menand and al. \cite{Menand2024link} recently developed the new metric $VCMPR@k$, to evaluate link prediction task in graph representation learning.
They claimed that the AUC metric using dot product similarities surestimates the embedding quality measures.
Here we identify factors biasing $VCMPR@k$ to low values.


\section{Low value bias of VCMPR@k}
As many for real-world graphs, nodes degrees follow a power law distribution, a large fraction of nodes may have degree much lower than the mean degree.
This impacts the $VCMPR@k$ formula $ VCMPR_{i}(k)= \frac{t_{i}(k)}{\min(d_{i},k)}$ as a node with no incident edge deleted contributes to 0 in the $VCMPR@k$ formula.

With an edge deletion probability $p$ of 0.2, on average only nodes of degree greater or equal than 5 can contribute significantly. Precisely the binomial distribution implies that nodes of degree less than 4 will contribute 0 with probability at least 0.41.
For the Amazon graph, degrees quantiles show we can expect 50\% of nodes to have zero contribution (simulation shows it is 40\%).
Degrees quantiles for the Blog and Amazon graph are given at \href{https://github.com/jean-pierreBoth/linkauc/tree/master/Degrees}{\color{blue}Degrees}).
In the same way: if the number of deleted edges is less than $min(d_{i},k)$, which is expected for $p \cdot d_{i} \leq k$, the score of a node will be less than 1 even if all edges are retrieved.
If a large proportion of nodes satisfy $d_{i} \le k$ we should expect $vcmpr$ to be around $p$. For example in the Amazon graph 90\% of nodes have degree less than 10.\\
More apriori estimations can be found on a detailed version of this note \href{https://github.com/jean-pierreBoth/linkauc/tree/master/Latex}{\color{blue}linkauc-long.tex}
Alternatively a Julia script in \href{https://github.com/jean-pierreBoth/linkauc/tree/master/Degrees}{\color{blue}Degrees/e\_vcmpr.jl} can compute expectations over quantiles degrees.
To avoid the problem of degree distribution we propose the following new metric.

\section{A centric AUC}

We let $i$ be a node, $d_{i}$ be its degree, $r_{i}$ the number of deleted edges incident to $i$.
So, after edge deletion, a node $i$ has degree $d_{i} - r_{i}$ and we have  $ n - 1 - (d_{i} - r_{i})$  potential edges to test
Given a node $i$ we sort the n-1 edges by decreasing prediction of existence of a true edge between i and j. We define $c_{j}$  as the number of true edges seen up to j.
When exploring the j-th node there are 2 possibilities:
\begin{itemize}
    \item j corresponds to a train edge, we increment $c_{j}$ by 1
    \item j corresponds to a deleted edge. As our array is sorted, the probability that this edge has a higher
          ranking than a random edge is simply the ratio of potential edges after j to
          the total number of potential edges $ \frac{n-j-(d_{i}-r_{i}(-c_{j}))}{n-1-(d_{i}-r_{i})}$
\end{itemize}
Averaging over deleted edge indexes $j$ this defines a centric AUC at  $i$, then averaging over uniformly sampled nodes $i$ we get a centric AUC.
We tested this centric AUC with the HOPE \citep{Ou2016asymmetric} and NodeSketch \citep{Yang2019nodesketch} embeddings implemented
in our software \href{https://github.com/jean-pierreBoth/graphembed}{\color{blue}graphembed}.

\subsection{Results}

Results of some graph embeddings are given in Table 1 below. The Blog graph has a smaller centric AUC than the global AUC in each embedding but in a less pronounced way than that of \textit{vcmpr}. The Amazon and Dblp graph has a similar centric AUC with global AUC in each embedding.

\begin{table}[ht]
    \caption{Embedding parameters and AUC}
    \begin{tabular*}{\textwidth}[]{p{1.8cm}@{\extracolsep\fill}ccccccc}
        \toprule
        Graph &  Algo Parameters & Centric AUC &  Global AUC  \\
        \midrule
        \multicolumn{5}{l}{A. Sketching results. Parameters given in a triplet: dimension, nbhops, decay}\\
        Blog   & 1000,5,0.5 & $0.681 \pm \num{5.9E-3}$ & 0.93 \\
        Amazon & 1000,5,0.5 & $0.961 \pm \num{4E-3}$    & $ 0.978 \pm \num{3.2E-4}$ \\
        Dblp   & 1000,5,0.5 & $0.918 \pm \num{6E-3}$    & $ 0.901 \pm \num{6.6E-4}$ \\
        Dblp   & 400,4,0.4  & $0.94 \pm \num{5.1E-3}$   & $ 0.961 \pm \num{4.4E-4}$ \\
        \midrule
        \multicolumn{5}{l}{B. Hope embedding. Parameters given in a couple: dimension, nb iterations}\\
        Blog   & 400,5      & $0.698 \pm \num{7.4E-3}$  & 0.952 \\
        Amazon & 400,5      & $0.834 \pm \numprint{6.4E-3}$    & $ 0.856 \pm \num{9.1E-4}$ \\
        \bottomrule
    \end{tabular*}
    \label{t:table2}\end{table}



\section{Conclusion}
The gap between $vcmpr@k$ and AUC seems more related to the gap between precision and AUC than to its centric aspect.

\bibliography{625333_0_supp_latex_10774582_sbxt8w}
\end{document}